{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43b6d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.py(with time)\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import random\n",
    "from run import DogSimilarityClassifier, ResNetFeatureExtractor\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7545e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbaa558",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4143c7ac",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Define custom dataset class for flat directory\n",
    "class CustomDogDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "\n",
    "        for file in os.listdir(root_dir):\n",
    "            if file.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "                self.image_paths.append(os.path.join(root_dir, file))\n",
    "        \n",
    "        if not self.image_paths:\n",
    "            raise ValueError(f\"No images found in directory: {root_dir}\")\n",
    "\n",
    "        self.labels = [0] * len(self.image_paths)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = self.labels[idx]\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4ceaf8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Define Triplet Loss\n",
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, anchor, positive, negative):\n",
    "        positive_distance = torch.nn.functional.pairwise_distance(anchor, positive)\n",
    "        negative_distance = torch.nn.functional.pairwise_distance(anchor, negative)\n",
    "        loss = torch.nn.functional.relu(positive_distance - negative_distance + self.margin)\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd02790c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Create triplets from your data\n",
    "def generate_triplets(dataset, batch_size=32):\n",
    "    dataset_size = len(dataset)\n",
    "    triplets = []\n",
    "\n",
    "    while len(triplets) < dataset_size:\n",
    "        indices = random.sample(range(dataset_size), 3)\n",
    "        anchor, positive, negative = dataset[indices[0]][0], dataset[indices[1]][0], dataset[indices[2]][0]\n",
    "        triplets.append((anchor, positive, negative))\n",
    "\n",
    "    return DataLoader(triplets, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad3e46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Define the root directory containing dog images\n",
    "    root_dir = r\"E:\\gpu\\Sphase\\samedog6\\data\\football_database\"\n",
    "\n",
    "    # Load dataset\n",
    "    train_dataset = CustomDogDataset(root_dir, transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "    # Instantiate the ResNet model\n",
    "    feature_extractor = ResNetFeatureExtractor().to(device)\n",
    "    model = DogSimilarityClassifier(feature_extractor).to(device)\n",
    "\n",
    "    # Define loss function and optimizer\n",
    "    criterion = TripletLoss(margin=1.0)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "    # Mixed precision training\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    # Record start time\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 1\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for triplet in generate_triplets(train_dataset, batch_size=32):\n",
    "            anchor, positive, negative = triplet\n",
    "            anchor, positive, negative = anchor.to(device, non_blocking=True), positive.to(device, non_blocking=True), negative.to(device, non_blocking=True)\n",
    "            optimizer.zero_grad()\n",
    "            with torch.cuda.amp.autocast():\n",
    "                anchor_out = model(anchor)\n",
    "                positive_out = model(positive)\n",
    "                negative_out = model(negative)\n",
    "                loss = criterion(anchor_out, positive_out, negative_out)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            running_loss += loss.item() * anchor.size(0)\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    # Record end time\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    print(f\"Total training time: {total_time:.2f} seconds\")\n",
    "\n",
    "    # Save the trained model\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    torch.save(model.state_dict(), \"models/dog_similarity_resnet50_triplet.pth\")\n",
    "    torch.save(feature_extractor.state_dict(), \"models/resnet_feature_extractor.pth\")\n",
    "\n",
    "    print(\"Training finished and model saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd6815b",
   "metadata": {},
   "source": [
    "#==========================================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911f3e6e",
   "metadata": {},
   "source": [
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import random\n",
    "from run import DogSimilarityClassifier, ResNetFeatureExtractor\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0fc16b",
   "metadata": {},
   "source": [
    "# Define device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a554a052",
   "metadata": {},
   "source": [
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca311e71",
   "metadata": {},
   "source": [
    "# Define custom dataset class for flat directory\n",
    "class CustomDogDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96eeae51",
   "metadata": {},
   "source": [
    "        for file in os.listdir(root_dir):\n",
    "            if file.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "                self.image_paths.append(os.path.join(root_dir, file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4402986",
   "metadata": {},
   "source": [
    "        if not self.image_paths:\n",
    "            raise ValueError(f\"No images found in directory: {root_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a177bb2",
   "metadata": {},
   "source": [
    "        # Filter out corrupted images\n",
    "        self.image_paths = self.filter_corrupted_images(self.image_paths)\n",
    "        self.labels = [0] * len(self.image_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20096582",
   "metadata": {},
   "source": [
    "    def filter_corrupted_images(self, image_paths):\n",
    "        valid_paths = []\n",
    "        for img_path in image_paths:\n",
    "            try:\n",
    "                with Image.open(img_path) as img:\n",
    "                    img.verify()  # Verify that the file is a readable image\n",
    "                valid_paths.append(img_path)\n",
    "            except (OSError, UnidentifiedImageError):\n",
    "                print(f\"Skipping corrupted image: {img_path}\")\n",
    "        return valid_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbfa0a9",
   "metadata": {},
   "source": [
    "    def __len__(self):\n",
    "        return len(self.image_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571e25f4",
   "metadata": {},
   "source": [
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "        except (OSError, UnidentifiedImageError) as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "            return None  # Return None if image is corrupted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd28c23",
   "metadata": {},
   "source": [
    "        if self.transform:\n",
    "            image = self.transform(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4a15a3",
   "metadata": {},
   "source": [
    "        label = self.labels[idx]\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c22716",
   "metadata": {},
   "source": [
    "# Define Triplet Loss\n",
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51473922",
   "metadata": {},
   "source": [
    "    def forward(self, anchor, positive, negative):\n",
    "        positive_distance = torch.nn.functional.pairwise_distance(anchor, positive)\n",
    "        negative_distance = torch.nn.functional.pairwise_distance(anchor, negative)\n",
    "        loss = torch.nn.functional.relu(positive_distance - negative_distance + self.margin)\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef8fe90",
   "metadata": {},
   "source": [
    "# Create triplets from your data\n",
    "def generate_triplets(dataset, batch_size=32):\n",
    "    triplets = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f39e90",
   "metadata": {},
   "source": [
    "    while len(triplets) < len(dataset):\n",
    "        indices = random.sample(range(len(dataset)), 3)\n",
    "        anchor, positive, negative = dataset[indices[0]], dataset[indices[1]], dataset[indices[2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946a8ac9",
   "metadata": {},
   "source": [
    "        if None not in (anchor, positive, negative):\n",
    "            anchor_img, _ = anchor\n",
    "            positive_img, _ = positive\n",
    "            negative_img, _ = negative\n",
    "            triplets.append((anchor_img, positive_img, negative_img))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23787fb",
   "metadata": {},
   "source": [
    "    return DataLoader(triplets, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd91ea3c",
   "metadata": {},
   "source": [
    "if __name__ == '__main__':\n",
    "    # Define the root directory containing dog images\n",
    "    root_dir = r\"E:\\gpu\\Sphase\\samedog6\\data\\football_database\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56773ec",
   "metadata": {},
   "source": [
    "    # Load dataset\n",
    "    train_dataset = CustomDogDataset(root_dir, transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252c949b",
   "metadata": {},
   "source": [
    "    # Instantiate the ResNet model\n",
    "    feature_extractor = ResNetFeatureExtractor().to(device)\n",
    "    model = DogSimilarityClassifier(feature_extractor).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6052e7d7",
   "metadata": {},
   "source": [
    "    # Define loss function and optimizer\n",
    "    criterion = TripletLoss(margin=1.0)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2978ab90",
   "metadata": {},
   "source": [
    "    # Mixed precision training\n",
    "    scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f70bbf",
   "metadata": {},
   "source": [
    "    # Record start time\n",
    "    start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621572c3",
   "metadata": {},
   "source": [
    "    # Training loop\n",
    "    num_epochs = 1\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for triplet in generate_triplets(train_dataset, batch_size=32):\n",
    "            anchor, positive, negative = triplet\n",
    "            anchor, positive, negative = anchor.to(device, non_blocking=True), positive.to(device, non_blocking=True), negative.to(device, non_blocking=True)\n",
    "            optimizer.zero_grad()\n",
    "            with torch.cuda.amp.autocast():\n",
    "                anchor_out = model(anchor)\n",
    "                positive_out = model(positive)\n",
    "                negative_out = model(negative)\n",
    "                loss = criterion(anchor_out, positive_out, negative_out)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            running_loss += loss.item() * anchor.size(0)\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a0a4bc",
   "metadata": {},
   "source": [
    "    # Record end time\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    print(f\"Total training time: {total_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a1db4d",
   "metadata": {},
   "source": [
    "    # Save the trained model\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    torch.save(model.state_dict(), \"models/dog_similarity_resnet50_triplet.pth\")\n",
    "    torch.save(feature_extractor.state_dict(), \"models/resnet_feature_extractor.pth\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "ame",
   "language": "python",
   "name": "ame"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
